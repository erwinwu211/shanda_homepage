<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description"
    content="Diffuman4D enables high-fidelity free-viewpoint rendering of human performances from sparse-view videos.">
  <meta property="og:title" content="Towards Interactive Intelligence for Digital Humans" />
  <meta property="og:description"
    content="Diffuman4D enables high-fidelity free-viewpoint rendering of human performances from sparse-view videos." />
  <meta property="og:url" content="https://diffuman4d.github.io/" />
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/images/teaser_1200x600.jpg" />
  <meta property="og:image:width" content="1200" />
  <meta property="og:image:height" content="600" />


  <meta name="twitter:title" content="Towards Interactive Intelligence for Digital Humans">
  <meta name="twitter:description"
    content="Diffuman4D enables high-fidelity free-viewpoint rendering of human performances from sparse-view videos.">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/teaser_1200x600.jpg">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Towards Interactive Intelligence for Digital Humans</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.png">
  <link href="https://fonts.googleapis.com/css?family=Lato" rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>

<body>
  <!-- > Hero -->
  <section class="section has-background-black has-text-white" id="section_hero">
    <div class="container is-max-desktop has-text-centered">
      <!-- > Title -->
      <div class="columns is-centered">
        <div class="column">
          <h1 class="title publication-title">
            <span class="pub-subtitle">Towards Interactive Intelligence for Digital Humans</span>
          </h1>
          <div class="is-size-5 publication-authors">
            <!-- Paper authors -->
           <span class="author-block">
                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">Yiyi Cai</a><sup>1</sup>,</span>
                <span class="author-block">
                  <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Xuangeng Chu</a><sup>1,2</sup>,</span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Xiwei Gao</a><sup>1</sup>,
                  </span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Sitong Gong</a><sup>1</sup>,
                  </span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Yifei Huang</a><sup>1,2</sup>,
                  </span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Caixin Kang</a><sup>1,2</sup>,
                  </span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Kunhang Li</a><sup>1</sup>,
                  </span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Ruicong Liu</a><sup>1,2</sup>,
                  </span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Haiyang Liu</a><sup>1</sup>,
                  </span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Yun Liu</a><sup>1</sup>,
                  </span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Dianwen Ng</a><sup>1</sup>ï¼Œ
                  </span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Zixiong Su</a><sup>1</sup>,
                  </span>
                  <span class="author-block">
                    <a href="https://www.erwin-wu.com/" target="_blank">Erwin Wu</a><sup>1,3</sup>,
                  </span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Yuhan Wu</a><sup>1</sup>,
                  </span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Tianyu Wu</a><sup>1</sup>,
                  </span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Dingkun Yan</a><sup>1</sup>,
                  </span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Chang Zeng</a><sup>1</sup>,
                  </span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Bo Zheng</a><sup>1</sup>,
                  </span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">You Zhou</a><sup>1</sup>
                  </span>
                  </div>
          <!-- Authors affiliation -->
          <div class="publication-authors">
            <div class="is-size-5">
             <span class="eql-cntrb"><small>Authors are listed in alphabetical order of their last name.</small></span><br>
                    <span class="author-block"><sup>1</sup>Shanda AI Research Tokyo, <br> <sup>2</sup>The University of Tokyo, <sup>3</sup>Institute of Science Tokyo </span>
                       </div>
            
          <!-- Conference
          <div class="is-size-5 publication-conference">ICCV 2025</div>-->
          <!-- Links -->
          <div class="column">
            <div class="publication-links">
              <span class="link-block">
                <a href="https://arxiv.org/abs/2507.13344" target="_blank"
                  class="external-link button is-normal is-rounded is-light">
                  <span class="icon"><i class="fas fa-file-pdf"></i></span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://github.com/zju3dv/Diffuman4D" target="_blank"
                  class="external-link button is-normal is-rounded is-light">
                  <span class="icon"><i class="fab fa-github"></i></span>
                  <span>Code</span>
                </a>
              </span>
              <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  ðŸ¤— Hugging Face
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
      <!-- > Teaser video-->
      <div class="publication-video">
        <video poster="" id="teaser" controls loop muted playsinline autoplay>
          <source src="static/videos/teaser.mp4" type="video/mp4">
        </video>
      </div>
      <div class="content">
        <p>Demo video of MIO.</p>
      </div>
    </div>
  </section>


  <!-- > Intro -->
  <section class="section has-background-black has-text-white" id="section_method">
    <div class="container is-max-desktop has-text-centered">
      <h2 class="title">Introduction</h2>
      <div class="content has-text-left">
        <p>Most existing digital humans remain primarily imitative, reproducing surface patterns of behavior
without genuine interactive intelligenceâ€”the ability to generate real-time, emotionally coherent
responses with consistent personality across voice, face and body motions, appearance.</p>

<p>We model digital humans as autonomous agents with personality-consistent expression, adaptive
interaction, and self-evolution, and propose a cascading paradigm composed of five modules: <b>Thinker</b>,
<b>Talker</b>, <b>Facial Animator</b>, <b>Body Animator</b>, and <b>Renderer</b>. The Thinker performs contextual reasoning and
control, while the remaining modules generate coordinated speech, facial motion, body motion, and
final visual appearance in an end-to-end controllable manner.</p>

<p>We further introduce a <b>new benchmark for interactive intelligence</b> evaluating speech, expression, motion,
visual style, and personality consistency. Together, these contributions move digital humans beyond
superficial imitation toward truly intelligent interaction. </p>
        </ol>
      </div>
      <div class="figure-container">
        <img src="static/images/pipeline.jpg" alt="Diffuman4D pipeline">
      </div>
    </div>
  </section>

  <!-- > Dataset -->
  <section class="section has-background-black has-text-white" id="section_dataset">
    <div class="container is-max-desktop has-text-centered">
      <h2 class="title">Dataset</h2>
      <div class="content has-text-left">
        <p>To enable model training, we meticulously process the <a href="https://dna-rendering.github.io/index.html"
            target="_blank">DNA-Rendering dataset</a> by recalibrating camera parameters, optimizing image color
          correction matrices (CCMs), predicting foreground masks, and estimating human skeletons.</p>
        <p>To promote future research in the field of human-centric 3D/4D generation, we have open-sourced our
          re-annotated labels for the DNA-Rendering dataset in <a
            href="https://huggingface.co/datasets/krahets/dna_rendering_processed"
            target="_blank">dna_rendering_processed</a>, which includes 1000+ human multi-view video sequences. Each
          sequence contains 48 cameras, 225 (or 150) frames, totaling 10 million images.</p>
      </div>
      <!-- > Dataset video-->
      <div class="publication-video">
        <video poster="" id="dataset" controls loop muted playsinline autoplay>
          <source src="static/videos/dna_rendering_processed.mp4" type="video/mp4">
        </video>
      </div>
    </div>
  </section>

  <!-- > Acknowledgments -->
  <section class="section has-background-black has-text-white" id="section_acknowledgments">
    <div class="container is-max-desktop">
      <h2 class="title">Acknowledgments</h2>
      <p>We would like to thank XXXXXX.</p>
    </div>
  </section>

  <!-- > BibTex citation -->
  <section class="section has-background-black has-text-white" id="section_bibtex">
    <div class="container is-max-desktop">
      <h2 class="title">BibTeX</h2>
      <pre><code class="is-small">TODO</code></pre>
    </div>
  </section>

  <!-- > Footer -->
  <footer class="footer has-background-black has-text-white">
    <div class="container is-max-desktop" style="margin-top: 2rem; padding-top: 2rem; border-top: 1px solid #1C1C1E;">
      <p>This page was built using <a href="https://github.com/eliahuhorwitz/Academic-project-page-template"
          target="_blank">Academic Project Page Template</a>. The website's design was inspired by <a
          href="https://cat-4d.github.io/" target="_blank">CAT4D</a> and <a href="https://cat3d.github.io/"
          target="_blank">CAT3D</a>.</p>
    </div>
  </footer>

  <!-- > Overview video switcher -->
  <script>
    document.addEventListener('DOMContentLoaded', () => {
      const pills = document.querySelectorAll('.title-pill');
      const videos = document.querySelectorAll('.overview-pills .video-wrapper video');
      const DEFAULT = 'sparse_view_gs';

      function showVideo(label) {
        videos.forEach(v => {
          const active = v.dataset.label === label;
          v.hidden = !active;
          if (active) {
            v.currentTime = 0;
            v.play();
          } else {
            v.pause();
          }
        });
      }

      pills.forEach(pill => pill.addEventListener('click', () => {
        if (pill.classList.contains('active')) return;
        pills.forEach(el => el.classList.toggle('active', el === pill));
        showVideo(pill.dataset.label);
      }));

      showVideo(DEFAULT);
    });
  </script>

  <!-- > Comparisons video switcher -->
  <script>
    document.addEventListener('DOMContentLoaded', () => {
      const compareDiv = document.querySelector('#comparisons');
      const pills = compareDiv.querySelectorAll('.scene-pill');
      const v = document.getElementById('comparisons-video');
      const default_scene = 'dnar_0166_04';

      function loadScene(label) {
        v.src = `static/videos/comparisons/${label}.mp4`;
        v.load();
      }

      v.addEventListener('loadeddata', () => v.play());

      pills.forEach(p => p.addEventListener('click', () => {
        pills.forEach(el => el.classList.toggle('active', el === p));
        loadScene(p.dataset.value);
      }));

      loadScene(default_scene);
    });
  </script>

</body>

</html>